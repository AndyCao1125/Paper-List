# Robot Foundation Models

- [arXiv 2024.12](https://arxiv.org/abs/2412.14803), **Video Prediction Policy**: A Generalist Robot Policy with Predictive Visual Representations, [website](https://video-prediction-policy.github.io/)
- [arXiv 2024.12](https://arxiv.org/abs/2412.14058), Towards Generalist Robot Policies: **What Matters in Building Vision-Language-Action Models**, [website](https://robovlms.github.io/)
- [arXiv 2024.12](https://arxiv.org/abs/2412.15109), **Predictive Inverse Dynamics Models** are Scalable Learners for Robotic Manipulation
- [arXiv 2024.12](https://arxiv.org/abs/2412.13877), **RoboMIND**: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation
- [arXiv 2024.12](https://arxiv.org/abs/2412.09858), **RLDG**: Robotic Generalist Policy Distillation via Reinforcement Learning, [website](https://generalist-distillation.github.io/)
- [arXiv 2024.12](https://arxiv.org/abs/2412.04453), **NaVILA**: Legged Robot Vision-Language-Action Model for Navigation, [website](https://navila-bot.github.io/)
- [arXiv 2024.08](https://arxiv.org/abs/2408.15980), **ICRT**: In-Context Imitation Learning via Next-Token Prediction, [website](https://icrt.dev/) / [github](https://github.com/Max-Fu/icrt)
- [arXiv 2024.06](https://arxiv.org/abs/2406.11815), **LLARVA**: Vision-Action Instruction Tuning Enhances Robot Learning, [website](https://llarva24.github.io/)
- [arXiv 2024.06](https://arxiv.org/abs/2406.09246), **OpenVLA**: An Open-Source Vision-Language-Action Model, [website](https://openvla.github.io/)
- [arXiv 2024.05](https://arxiv.org/abs/2405.12213), **Octo**: An Open-Source Generalist Robot Policy, [websie](https://octo-models.github.io/) / [github](https://github.com/octo-models/octo)

# Robot World Models
[link](https://github.com/QinengWang-Aiden/Awesome-embodied-world-model-papers)
